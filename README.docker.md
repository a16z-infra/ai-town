# ðŸ  AI Town - Docker Hub

[![Docker Pulls](https://img.shields.io/docker/pulls/lingelo/ai-town)](https://hub.docker.com/r/lingelo/ai-town)
[![Docker Image Size](https://img.shields.io/docker/image-size/lingelo/ai-town)](https://hub.docker.com/r/lingelo/ai-town)
[![GitHub](https://img.shields.io/github/license/Lingelo/ai-town)](https://github.com/Lingelo/ai-town)

Une ville virtuelle oÃ¹ les personnages IA vivent, discutent et socialisent. Image Docker prÃªte Ã  l'emploi avec support multilingue et intÃ©gration OpenRouter.

## ðŸš€ DÃ©marrage rapide

### Utilisation simple (frontend seulement)
```bash
docker run -p 80:80 lingelo/ai-town:latest
```

### DÃ©ploiement complet avec backend
```bash
# TÃ©lÃ©charger la configuration
curl -o docker-compose.yml https://raw.githubusercontent.com/Lingelo/ai-town/main/docker-compose.hub.yml

# DÃ©marrer tous les services
docker compose up -d
```

### Avec configuration personnalisÃ©e
```bash
# CrÃ©er un fichier .env
cat > .env << EOF
VITE_LANGUAGE=fr
FRONTEND_PORT=80
PORT=3210
DASHBOARD_PORT=6791
INSTANCE_NAME=my-ai-town
EOF

# DÃ©marrer avec la configuration
docker compose up -d
```

## ðŸŒ Support multilingue

### FranÃ§ais
```bash
docker run -p 80:80 -e VITE_LANGUAGE=fr lingelo/ai-town:latest
```

### Portugais
```bash
docker run -p 80:80 -e VITE_LANGUAGE=pt lingelo/ai-town:latest
```

### Anglais (dÃ©faut)
```bash
docker run -p 80:80 -e VITE_LANGUAGE=en lingelo/ai-town:latest
```

## ðŸ¤– Configuration LLM

Cette image supporte plusieurs providers d'IA :

### OpenRouter (RecommandÃ©)
```bash
# Variables d'environnement pour OpenRouter
LLM_PROVIDER=openrouter
OPENROUTER_API_KEY=sk-or-v1-your-key
OPENROUTER_CHAT_MODEL=anthropic/claude-3.5-sonnet
```

### Ollama (Local)
```bash
# Variables d'environnement pour Ollama
OLLAMA_HOST=http://your-ollama-host:11434
OLLAMA_MODEL=llama3.1:latest
```

## ðŸ“‹ Services inclus

| Service | Port | Description |
|---------|------|-------------|
| Frontend | 80 | Interface web AI Town |
| Backend | 3210 | Serveur Convex |
| Dashboard | 6791 | Interface d'administration |

## ðŸ”§ Configuration avancÃ©e

### Variables d'environnement complÃ¨tes

```bash
# Application
VITE_LANGUAGE=fr                    # Langue (en/fr/pt)
FRONTEND_PORT=80                    # Port frontend
INSTANCE_NAME=my-ai-town           # Nom de l'instance

# Backend Convex
PORT=3210                          # Port backend
SITE_PROXY_PORT=3211              # Port proxy
DASHBOARD_PORT=6791                # Port dashboard

# LLM Provider (choisir un)
LLM_PROVIDER=openrouter            # ou ollama/openai
OPENROUTER_API_KEY=your-key        # ClÃ© OpenRouter
OPENROUTER_CHAT_MODEL=anthropic/claude-3.5-sonnet
```

### Personnages personnalisÃ©s

L'image inclut des personnages par dÃ©faut (Angelo, MÃ©lanie, Jenna) mais vous pouvez les personnaliser en montant votre propre configuration :

```bash
docker run -p 80:80 \
  -v ./my-characters.json:/usr/share/nginx/html/config/characters.json \
  lingelo/ai-town:latest
```

## ðŸ³ Docker Compose complet

TÃ©lÃ©chargez et utilisez notre configuration prÃªte Ã  l'emploi :

```bash
# TÃ©lÃ©charger
wget https://raw.githubusercontent.com/Lingelo/ai-town/main/docker-compose.hub.yml

# Configurer
cp docker-compose.hub.yml docker-compose.yml

# CrÃ©er la configuration
cat > .env << EOF
VITE_LANGUAGE=fr
LLM_PROVIDER=openrouter
OPENROUTER_API_KEY=your-key-here
EOF

# DÃ©marrer
docker compose up -d
```

## ðŸ“Š Monitoring

### Health Checks
```bash
# VÃ©rifier le statut
docker compose ps

# Logs des services
docker compose logs -f frontend
docker compose logs -f backend
```

### Surveillance des coÃ»ts
- OpenRouter : [openrouter.ai/activity](https://openrouter.ai/activity)
- Estimation : ~$0.10-0.50/heure pour 5 personnages actifs

## ðŸ”„ Mise Ã  jour

```bash
# Mettre Ã  jour l'image
docker compose pull frontend

# RedÃ©marrer avec la nouvelle version
docker compose up -d
```

## ðŸ› ï¸ DÃ©pannage

### ProblÃ¨mes courants

**Frontend ne se charge pas**
```bash
docker logs ai-town-frontend-1
```

**Backend ne rÃ©pond pas**
```bash
# VÃ©rifier la santÃ© du backend
docker compose exec backend curl http://localhost:3210/version
```

**Erreurs LLM**
```bash
# VÃ©rifier les variables d'environnement
docker compose exec backend env | grep -E "(OPENROUTER|OLLAMA)"
```

### Reset complet
```bash
# ArrÃªter et nettoyer
docker compose down -v

# RedÃ©marrer
docker compose up -d
```

## ðŸ“š Documentation

- **Code source** : [github.com/Lingelo/ai-town](https://github.com/Lingelo/ai-town)
- **OpenRouter** : [docs/OPENROUTER.md](https://github.com/Lingelo/ai-town/blob/main/docs/OPENROUTER.md)
- **AI Town original** : [github.com/a16z-infra/ai-town](https://github.com/a16z-infra/ai-town)

## ðŸ¤ Support

- **Issues** : [GitHub Issues](https://github.com/Lingelo/ai-town/issues)
- **Discussions** : [GitHub Discussions](https://github.com/Lingelo/ai-town/discussions)

## ðŸ“„ Licence

MIT License - Voir [LICENSE](https://github.com/Lingelo/ai-town/blob/main/LICENSE)